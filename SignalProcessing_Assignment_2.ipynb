{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1bb82882",
      "metadata": {
        "id": "1bb82882"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcharos/Image-Classification-SVM/blob/main/SignalProcessing_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f539bdb0",
      "metadata": {
        "id": "f539bdb0"
      },
      "source": [
        "# AIDL Assignment 2 – Image Classification (MNIST)\n",
        "\n",
        "Skeleton notebook for experimentation and implementation.\n",
        "Fill in the code sections as required. Do **not** include answers here; analysis and results should go into the PDF report."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2f432f1",
      "metadata": {
        "id": "f2f432f1"
      },
      "source": [
        "## Imports and Global Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3769808b",
      "metadata": {
        "id": "3769808b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "import time\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "vH2dMwy4wsWf"
      },
      "id": "vH2dMwy4wsWf"
    },
    {
      "cell_type": "markdown",
      "id": "4020c070",
      "metadata": {
        "id": "4020c070"
      },
      "source": [
        "## 1. Load and Inspect the MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c82c4e17",
      "metadata": {
        "id": "c82c4e17"
      },
      "outputs": [],
      "source": [
        "# 1. Setup Directory\n",
        "dataset_dir = './dataset'\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "    print(f\"Created directory: {dataset_dir}\")\n",
        "\n",
        "# 2. Download Dataset\n",
        "url = \"http://www.di.ens.fr/~lelarge/MNIST.tar.gz\"\n",
        "target_path = os.path.join(dataset_dir, \"MNIST.tar.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65f1dde8",
      "metadata": {
        "id": "65f1dde8"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(target_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(target_path, \"wb\") as f:\n",
        "        f.write(response.raw.read())\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "if os.path.exists(target_path):\n",
        "    print(\"Extracting files...\")\n",
        "with tarfile.open(target_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=dataset_dir)\n",
        "print(\"Extraction complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a464a18f",
      "metadata": {
        "id": "a464a18f"
      },
      "outputs": [],
      "source": [
        "train_set = datasets.MNIST(root=dataset_dir, train=True, download=False)\n",
        "test_set = datasets.MNIST(root=dataset_dir, train=False, download=False)\n",
        "\n",
        "X_train = train_set.data.numpy()\n",
        "y_train = train_set.targets.numpy()\n",
        "X_test = test_set.data.numpy()\n",
        "y_test = test_set.targets.numpy()\n",
        "\n",
        "print(f\"Training shape: {X_train.shape}\") # Should be (60000, 28, 28)\n",
        "print(f\"Testing shape: {X_test.shape}\")   # Should be (10000, 28, 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c09732c7",
      "metadata": {
        "id": "c09732c7"
      },
      "source": [
        "## 2. Data Regrouping (Binary Classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdfd276",
      "metadata": {
        "id": "6fdfd276"
      },
      "outputs": [],
      "source": [
        "# Convert labels to binary classes:\n",
        "# Class 1: digits 0–4, Class 2: digits 5–9\n",
        "\n",
        "y_train_binary = np.where(y_train < 5, 0, 1)\n",
        "y_test_binary = np.where(y_test < 5, 0, 1)\n",
        "\n",
        "# Verification\n",
        "print(f\"Original unique labels: {np.unique(y_train)}\")\n",
        "print(f\"New unique labels: {np.unique(y_train_binary)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verify the split\n",
        "\n",
        "indices = np.random.choice(len(X_train), 5, replace=False)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "for i, idx in enumerate(indices):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(X_train[idx], cmap='gray')\n",
        "\n",
        "    original_label = y_train[idx]\n",
        "    binary_label = y_train_binary[idx]\n",
        "\n",
        "    # Determine which class it belongs to for the title\n",
        "    class_name = \"Class 1\" if binary_label == 0 else \"Class 2\"\n",
        "\n",
        "    plt.title(f\"Orig: {original_label}\\nNew: {binary_label}\\n({class_name})\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3CFiEpSt3C9s"
      },
      "id": "3CFiEpSt3C9s",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3581ea00",
      "metadata": {
        "id": "3581ea00"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15466609",
      "metadata": {
        "id": "15466609"
      },
      "outputs": [],
      "source": [
        "# Flatten images (28x28 -> 784)\n",
        "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Normalization: Scale pixel values to the [0, 1] range\n",
        "X_train_flat = X_train_flat.astype('float32') / 255.0\n",
        "X_test_flat = X_test_flat.astype('float32') / 255.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sub-sampling the dataset\n",
        "# pick every 3rd vector and discards the rest\n",
        "X_train_final = X_train_flat[::3]\n",
        "y_train_final = y_train_binary[::3]\n",
        "\n",
        "# test set is the same\n",
        "X_test_final = X_test_flat\n",
        "y_test_final = y_test_binary"
      ],
      "metadata": {
        "id": "YoCX8w2K34wG"
      },
      "id": "YoCX8w2K34wG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a40d98dd",
      "metadata": {
        "id": "a40d98dd"
      },
      "source": [
        "## 3. SVM Benchmark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM GridSearch - Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "dgfCR-RY4W6h"
      },
      "id": "dgfCR-RY4W6h"
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = [\n",
        "    {\n",
        "        'kernel': ['poly'],\n",
        "        'C': [0.1, 1, 10],\n",
        "        'degree': [2, 3, 4, 5]  # Exploring polynomial degree\n",
        "    },\n",
        "    {\n",
        "        'kernel': ['rbf'],\n",
        "        'C': [0.1, 1, 10],\n",
        "        'gamma': ['scale', 'auto', 0.001, 0.01, 0.1] # Exploring Gamma\n",
        "    },\n",
        "    {\n",
        "        'kernel': ['linear'],\n",
        "        'C': [0.1, 1, 10]\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "rfaue6b95Fvw"
      },
      "id": "rfaue6b95Fvw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Grid search over C and kernels (linear, poly, rbf)\n",
        "# Explore degree (poly) and gamma (rbf)\n",
        "\n",
        "svc = SVC()\n",
        "\n",
        "grid_search = GridSearchCV(SVC(),\n",
        "                           param_grid,\n",
        "                           cv=3,\n",
        "                           scoring='accuracy',\n",
        "                           verbose=1\n",
        ")\n",
        "\n",
        "print(\"Starting Grid Search for SVM Benchmark...\")\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train_final, y_train_final)\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nGrid Search completed in {total_time:.2f} seconds\")\n",
        "print(f\"Best Hyperparameters found: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n"
      ],
      "metadata": {
        "id": "5KZfagrH4K9_"
      },
      "id": "5KZfagrH4K9_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15dc3485",
      "metadata": {
        "id": "15dc3485"
      },
      "outputs": [],
      "source": [
        "best_svm = grid_search.best_estimator_\n",
        "y_pred = best_svm.predict(X_test_final)\n",
        "benchmark_accuracy = accuracy_score(y_test_final, y_pred) * 100\n",
        "\n",
        "print(f\"SVM Benchmark Total Accuracy: {benchmark_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62481310",
      "metadata": {
        "id": "62481310"
      },
      "source": [
        "## 4. Dimensionality reduction via PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a200ba9c",
      "metadata": {
        "id": "a200ba9c"
      },
      "outputs": [],
      "source": [
        "# Apply PCA for different K values\n",
        "# Train SVM on PCA-reduced data\n",
        "# Store accuracy vs K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea77106",
      "metadata": {
        "id": "1ea77106"
      },
      "source": [
        "### PCA Accuracy Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55b35d31",
      "metadata": {
        "id": "55b35d31"
      },
      "outputs": [],
      "source": [
        "# Plot SVM accuracy as a function of K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e04e858d",
      "metadata": {
        "id": "e04e858d"
      },
      "source": [
        "## 5. Dimensionality reduction via LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85747f57",
      "metadata": {
        "id": "85747f57"
      },
      "outputs": [],
      "source": [
        "# Apply LDA (1D output)\n",
        "# Plot projected test data\n",
        "# Train and evaluate SVM on LDA features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85c813ea",
      "metadata": {
        "id": "85c813ea"
      },
      "source": [
        "## 6. Dimensionality reduction via PCA + LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb3699ab",
      "metadata": {
        "id": "eb3699ab"
      },
      "outputs": [],
      "source": [
        "# Apply PCA followed by LDA for different K\n",
        "# Train SVM and record accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74923d87",
      "metadata": {
        "id": "74923d87"
      },
      "source": [
        "## 7. Naïve Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78e2eb1",
      "metadata": {
        "id": "c78e2eb1"
      },
      "outputs": [],
      "source": [
        "# Train Gaussian Naïve Bayes\n",
        "# Handle near-zero variance issue (e.g., var smoothing)\n",
        "# Compare accuracy and computation time with SVM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "221abbe1",
      "metadata": {
        "id": "221abbe1"
      },
      "source": [
        "## 8. Summary (No Answers Here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ef4689d",
      "metadata": {
        "id": "0ef4689d"
      },
      "outputs": [],
      "source": [
        "# This section may include brief code comments only.\n",
        "# All discussion, plots, and conclusions go into the PDF report.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}