{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1bb82882",
      "metadata": {
        "id": "1bb82882"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcharos/Image-Classification-SVM/blob/main/SignalProcessing_Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f539bdb0",
      "metadata": {
        "id": "f539bdb0"
      },
      "source": [
        "# AIDL Assignment 2 – Image Classification (MNIST)\n",
        "\n",
        "Skeleton notebook for experimentation and implementation.\n",
        "Fill in the code sections as required. Do **not** include answers here; analysis and results should go into the PDF report."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2f432f1",
      "metadata": {
        "id": "f2f432f1"
      },
      "source": [
        "## Imports and Global Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3769808b",
      "metadata": {
        "id": "3769808b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import tarfile\n",
        "import numpy as np\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions"
      ],
      "metadata": {
        "id": "vH2dMwy4wsWf"
      },
      "id": "vH2dMwy4wsWf"
    },
    {
      "cell_type": "markdown",
      "id": "4020c070",
      "metadata": {
        "id": "4020c070"
      },
      "source": [
        "## 1. Load and Inspect the MNIST Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c82c4e17",
      "metadata": {
        "id": "c82c4e17",
        "outputId": "2462d220-abaf-41ef-f83c-765346d9328c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: ./dataset\n"
          ]
        }
      ],
      "source": [
        "# 1. Setup Directory\n",
        "dataset_dir = './dataset'\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "    print(f\"Created directory: {dataset_dir}\")\n",
        "\n",
        "# 2. Download Dataset\n",
        "url = \"http://www.di.ens.fr/~lelarge/MNIST.tar.gz\"\n",
        "target_path = os.path.join(dataset_dir, \"MNIST.tar.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "65f1dde8",
      "metadata": {
        "id": "65f1dde8",
        "outputId": "8720e306-20bd-4f01-b2fe-21177818feaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Download complete.\n",
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3377933242.py:11: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(path=dataset_dir)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(target_path):\n",
        "    print(\"Downloading dataset...\")\n",
        "    response = requests.get(url, stream=True)\n",
        "    with open(target_path, \"wb\") as f:\n",
        "        f.write(response.raw.read())\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "if os.path.exists(target_path):\n",
        "    print(\"Extracting files...\")\n",
        "with tarfile.open(target_path, \"r:gz\") as tar:\n",
        "    tar.extractall(path=dataset_dir)\n",
        "print(\"Extraction complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a464a18f",
      "metadata": {
        "id": "a464a18f",
        "outputId": "92c1f632-fa62-4753-b969-00038c6f9b60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training shape: (60000, 28, 28)\n",
            "Testing shape: (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "train_set = datasets.MNIST(root=dataset_dir, train=True, download=False)\n",
        "test_set = datasets.MNIST(root=dataset_dir, train=False, download=False)\n",
        "\n",
        "X_train = train_set.data.numpy()\n",
        "y_train = train_set.targets.numpy()\n",
        "X_test = test_set.data.numpy()\n",
        "y_test = test_set.targets.numpy()\n",
        "\n",
        "print(f\"Training shape: {X_train.shape}\") # Should be (60000, 28, 28)\n",
        "print(f\"Testing shape: {X_test.shape}\")   # Should be (10000, 28, 28)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c09732c7",
      "metadata": {
        "id": "c09732c7"
      },
      "source": [
        "## 2. Data Regrouping (Binary Classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fdfd276",
      "metadata": {
        "id": "6fdfd276"
      },
      "outputs": [],
      "source": [
        "# Convert labels to binary classes:\n",
        "# Class 1: digits 0–4, Class 2: digits 5–9\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3581ea00",
      "metadata": {
        "id": "3581ea00"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15466609",
      "metadata": {
        "id": "15466609"
      },
      "outputs": [],
      "source": [
        "# Flatten images (28x28 -> 784)\n",
        "# Optional normalization / scaling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a40d98dd",
      "metadata": {
        "id": "a40d98dd"
      },
      "source": [
        "## 3. SVM Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15dc3485",
      "metadata": {
        "id": "15dc3485"
      },
      "outputs": [],
      "source": [
        "# Train baseline SVM\n",
        "# Evaluate total classification accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fead02c",
      "metadata": {
        "id": "6fead02c"
      },
      "source": [
        "### SVM Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f72d26",
      "metadata": {
        "id": "67f72d26"
      },
      "outputs": [],
      "source": [
        "# Grid search over C and kernels (linear, poly, rbf)\n",
        "# Explore degree (poly) and gamma (rbf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62481310",
      "metadata": {
        "id": "62481310"
      },
      "source": [
        "## 4. Dimensionality reduction via PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a200ba9c",
      "metadata": {
        "id": "a200ba9c"
      },
      "outputs": [],
      "source": [
        "# Apply PCA for different K values\n",
        "# Train SVM on PCA-reduced data\n",
        "# Store accuracy vs K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ea77106",
      "metadata": {
        "id": "1ea77106"
      },
      "source": [
        "### PCA Accuracy Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55b35d31",
      "metadata": {
        "id": "55b35d31"
      },
      "outputs": [],
      "source": [
        "# Plot SVM accuracy as a function of K\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e04e858d",
      "metadata": {
        "id": "e04e858d"
      },
      "source": [
        "## 5. Dimensionality reduction via LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85747f57",
      "metadata": {
        "id": "85747f57"
      },
      "outputs": [],
      "source": [
        "# Apply LDA (1D output)\n",
        "# Plot projected test data\n",
        "# Train and evaluate SVM on LDA features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85c813ea",
      "metadata": {
        "id": "85c813ea"
      },
      "source": [
        "## 6. Dimensionality reduction via PCA + LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb3699ab",
      "metadata": {
        "id": "eb3699ab"
      },
      "outputs": [],
      "source": [
        "# Apply PCA followed by LDA for different K\n",
        "# Train SVM and record accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74923d87",
      "metadata": {
        "id": "74923d87"
      },
      "source": [
        "## 7. Naïve Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c78e2eb1",
      "metadata": {
        "id": "c78e2eb1"
      },
      "outputs": [],
      "source": [
        "# Train Gaussian Naïve Bayes\n",
        "# Handle near-zero variance issue (e.g., var smoothing)\n",
        "# Compare accuracy and computation time with SVM\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "221abbe1",
      "metadata": {
        "id": "221abbe1"
      },
      "source": [
        "## 8. Summary (No Answers Here)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ef4689d",
      "metadata": {
        "id": "0ef4689d"
      },
      "outputs": [],
      "source": [
        "# This section may include brief code comments only.\n",
        "# All discussion, plots, and conclusions go into the PDF report.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}